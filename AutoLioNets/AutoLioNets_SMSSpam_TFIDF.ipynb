{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install Keras==2.4.3\n",
    "!pip install tensorflow==2.3.0\n",
    "!pip install lime==0.1.1.32\n",
    "!pip install nltk==3.2.4\n",
    "!pip install autokeras\n",
    "!pip install keras-tuner==1.0.2rc3\n",
    "!pip install autoPyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Dense, LSTM, Dropout, Reshape\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras import Input, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.linear_model import Ridge, SGDRegressor, LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, f1_score, balanced_accuracy_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "pd.set_option('max_colwidth',400)\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "import nltk\n",
    "import seaborn as sns\n",
    "from load_dataset import Load_Dataset\n",
    "from LioNets import LioNet\n",
    "from evaluation import Evaluation\n",
    "import autokeras as ak\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "from autoPyTorch import AutoNetRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, class_names = Load_Dataset.load_smsspam()\n",
    "X_train, X_valid, y_train, y_valid =  train_test_split(X,y,test_size=0.2, stratify = y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = TfidfVectorizer(analyzer='word',max_features=1000)\n",
    "vec.fit(X_train)\n",
    "x_train = vec.transform(X_train).A\n",
    "x_valid = vec.transform(X_valid).A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(vec.get_feature_names())\n",
    "input_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = [0.1 if i <=0.5 else 0.9 for i in y_train]\n",
    "valid_y = [0.1 if i <=0.5 else 0.9 for i in y_valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_point = ModelCheckpoint(\"SMS_Predictor2020.hdf5\", monitor=\"val_loss\", verbose=2,save_best_only=True, mode=\"auto\")\n",
    "main_input = Input(shape=(input_dim,), dtype='float32', name='main_input')\n",
    "x = Reshape((1,input_dim))(main_input)\n",
    "x = LSTM(1000,activation='tanh')(x)\n",
    "x = Dropout(0.75)(x)\n",
    "x = Dense(500,activation='tanh')(x)\n",
    "output_lay = Dense(1, activation='sigmoid')(x)\n",
    "model = Model(inputs=[main_input], outputs=[output_lay])\n",
    "model.compile(optimizer=\"adam\",loss=['binary_crossentropy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_file = 'weights/SMS_Predictor.hdf5' # choose the best checkpoint few features\n",
    "model.load_weights(weights_file) # load it\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_predictor = model.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_pred = model.predict(x_train)\n",
    "predictions = [0 if i[0] <=0.5 else 1 for i in temp_pred]\n",
    "print('Train:',f1_score(y_train,predictions, average='macro'),f1_score(y_train,predictions, average='weighted'),\n",
    "      balanced_accuracy_score(y_train,predictions),accuracy_score(y_train,predictions))\n",
    "\n",
    "temp_pred = model.predict(x_valid)\n",
    "predictions = [0 if i[0] <=0.5 else 1 for i in temp_pred]\n",
    "print('Test:',f1_score(y_valid,predictions, average='macro'),f1_score(y_valid,predictions, average='weighted'),\n",
    "      balanced_accuracy_score(y_valid,predictions), accuracy_score(y_valid,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Model(inputs=model.input, outputs=[model.layers[-2].output])\n",
    "encoder.trainable = False\n",
    "encoder.compile(loss=\"binary_crossentropy\", optimizer=Adam(), metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_layer = model.layers[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_layer_weights = output_layer.get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_x_train = encoder.predict(x_train) #outputs of encoder / inputs of decoder\n",
    "encoded_x_valid = encoder.predict(x_valid)\n",
    "encoded_x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_input = Input(shape=(encoded_x_train[0].shape))\n",
    "\n",
    "x = Reshape((1,len(encoded_x_train[0])))(encoded_input)\n",
    "x = LSTM(600, activation='tanh')(x)\n",
    "x = Dropout(0.7)(x)\n",
    "x = Dense(800, activation='tanh')(x)\n",
    "decoded = Dense(input_dim, activation='sigmoid')(x)\n",
    "\n",
    "decoder = Model(encoded_input,decoded)\n",
    "decoder.compile(optimizer=\"Adam\",loss=['binary_crossentropy'],metrics=[rmse,'mae'])\n",
    "\n",
    "checkpoint_name = 'SMS_Decoder.hdf5' #or:'SMS_TFIDF_Decoder.hdf5' \n",
    "checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 2, save_best_only = True, mode ='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_file = 'weights/SMS_Decoder.hdf5' # choose the best checkpoint few features\n",
    "decoder.load_weights(weights_file) # load it\n",
    "decoder.compile(optimizer=\"Adam\",loss=['binary_crossentropy'],metrics=[rmse,'mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_decoder = decoder.predict(encoded_x_train)\n",
    "outputs_decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder.evaluate(encoded_x_train,x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder.evaluate(encoded_x_valid,x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances_evaluation = decoder.predict(encoded_x_train[:5]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances_evaluation_threshold = []\n",
    "for r_m in instances_evaluation:\n",
    "    a_t = [o if o > 0.045 else 0 for o in r_m]\n",
    "    instances_evaluation_threshold.append(a_t)\n",
    "inversed_decoded = vec.inverse_transform(instances_evaluation_threshold)\n",
    "inversed_original = vec.inverse_transform(x_train[:5])\n",
    "for i in range(len(inversed_original)):\n",
    "    print('Original:',' '.join(sorted(inversed_original[i])))\n",
    "    print(' Decoded:',' '.join(sorted(inversed_decoded[i])))\n",
    "    print('\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances_evaluation = decoder.predict(encoded_x_valid[:5]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances_evaluation_threshold = []\n",
    "for r_m in instances_evaluation:\n",
    "    a_t = [o if o > 0.045 else 0 for o in r_m]\n",
    "    instances_evaluation_threshold.append(a_t)\n",
    "inversed_decoded = vec.inverse_transform(instances_evaluation_threshold)\n",
    "inversed_original = vec.inverse_transform(x_valid[:5])\n",
    "for i in range(len(inversed_original)):\n",
    "    print('Original:',' '.join(sorted(inversed_original[i])))\n",
    "    print(' Decoded:',' '.join(sorted(inversed_decoded[i])))\n",
    "    print('\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoLioNets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run LioNets using AutoLioNets (decoder=\"auto\")\n",
    "#Time = [low, medium, high, None]\n",
    "lionet = LioNet(model, encoder, x_train, decoder=\"auto\", time=\"low\", decoder_lower_threshold=0.045, double_detector=True)\n",
    "#Original decoder-lionet\n",
    "lionet_original = LioNet(model, encoder, x_train, decoder, decoder_lower_threshold=0.045, double_detector=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate decoded instances\n",
    "lionet.print_examples(X_train=X_train, threshold=0.045)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set decoder with the best decoder from above evaluation\n",
    "best_decoder = lionet.load_best_decoder(0)\n",
    "lionet_best = LioNet(model, encoder, x_train, best_decoder, decoder_lower_threshold=0.045, double_detector=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To compute Fidelity for every strategy\n",
    "decoder1 = lionet.load_best_decoder(0)\n",
    "decoder2 = lionet.load_best_decoder(1)\n",
    "decoder3 = lionet.load_best_decoder(2)\n",
    "decoder4 = lionet.load_best_decoder(3)\n",
    "lionet_temp1 = LioNet(model, encoder, x_train, decoder1, decoder_lower_threshold=0.045, double_detector=True)\n",
    "lionet_temp2 = LioNet(model, encoder, x_train, decoder2, decoder_lower_threshold=0.045, double_detector=True)\n",
    "lionet_temp3 = LioNet(model, encoder, x_train, decoder3, decoder_lower_threshold=0.045, double_detector=True)\n",
    "lionet_temp4 = LioNet(model, encoder, x_train, decoder4, decoder_lower_threshold=0.045, double_detector=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fidelity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "#random.seed(2000)\n",
    "random.seed(7777)\n",
    "train = np.array(random.sample(X_train,100))#200\n",
    "valid = np.array(random.sample(X_valid,100))\n",
    "train.shape, valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fi_autolionets_s1(text):\n",
    "    t_text = vec.transform(np.array([text]))[0].A[0]\n",
    "    weights, res, loc_res = lionet_temp1.explain_instance(t_text,2000)\n",
    "    return loc_res\n",
    "\n",
    "def fi_autolionets_s2(text):\n",
    "    t_text = vec.transform(np.array([text]))[0].A[0]\n",
    "    weights, res, loc_res = lionet_temp2.explain_instance(t_text,2000)\n",
    "    return loc_res\n",
    "\n",
    "def fi_autolionets_s3(text):\n",
    "    t_text = vec.transform(np.array([text]))[0].A[0]\n",
    "    weights, res, loc_res = lionet_temp3.explain_instance(t_text,2000)\n",
    "    return loc_res\n",
    "\n",
    "def fi_autolionets_s4(text):\n",
    "    t_text = vec.transform(np.array([text]))[0].A[0]\n",
    "    weights, res, loc_res = lionet_temp4.explain_instance(t_text,2000)\n",
    "    return loc_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = Evaluation(model.predict,None,vec.transform,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fidelity = evaluator.fidelity(train[:100], [fi_autolionets_s1, fi_autolionets_s2, fi_autolionets_s3, \n",
    "                                            fi_autolionets_s4], class_n=0)\n",
    "print('AutoLioNets_S1 fidelity:', fidelity[0][0])\n",
    "print('AutoLioNets_S2 fidelity:', fidelity[1][0])\n",
    "print('AutoLioNets_S3 fidelity:', fidelity[2][0])\n",
    "print('AutoLioNets_S4 fidelity:', fidelity[3][0])\n",
    "fidelity = evaluator.fidelity(valid[:100], [fi_autolionets_s1, fi_autolionets_s2, fi_autolionets_s3, \n",
    "                                            fi_autolionets_s4], class_n=0)\n",
    "print('AutoLioNets_S1 fidelity:', fidelity[0][0])\n",
    "print('AutoLioNets_S2 fidelity:', fidelity[1][0])\n",
    "print('AutoLioNets_S3 fidelity:', fidelity[2][0])\n",
    "print('AutoLioNets_S4 fidelity:', fidelity[3][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qualitative Original Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_instance = x_train[9].copy()\n",
    "transparent_model = Ridge(alpha=0.0001,fit_intercept=True,random_state=0)\n",
    "weights, real_prediction, local_prediction = lionet_original.explain_instance(temp_instance[0:],2000, transparent_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str('Sentence: \"' + X_train[9] + '\"   Class: ' + str(train_y[9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, real_prediction, local_prediction = lionet_original.explain_instance(x_train[9][0:], 2000, transparent_model)\n",
    "print(\"Real prediction:\",real_prediction,\", Local prediction:\",local_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weights = pd.DataFrame({\"Features\": list(vec.get_feature_names()), \n",
    "                              \"Features' Weights\": list(weights*x_train[9][0:])})\n",
    "model_weights = model_weights.sort_values(by=\"Features' Weights\", ascending=False)\n",
    "model_weights = model_weights[(model_weights[\"Features' Weights\"] != 0)]    \n",
    "#model_weights, lime_predict([text])[0][1], rd.predict(texts)[0], weights\n",
    "plt.figure(num=None, figsize=(4, 3), dpi=200, facecolor='w', edgecolor='k')\n",
    "sns.barplot(x=\"Features' Weights\", y=\"Features\", data=model_weights)\n",
    "#plt.xticks(rotation=90)\n",
    "#plt.title(str('Features not appearing in the instance'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(weights),np.argmin(weights),np.max(weights),np.min(weights),vec.get_feature_names()[np.argmax(weights)],vec.get_feature_names()[np.argmin(weights)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_weights = []\n",
    "counter_features = []\n",
    "for i in range(len(weights)):\n",
    "    if weights[i]!=0:\n",
    "        if vec.get_feature_names()[i] not in X_train[9]:\n",
    "            counter_weights.append(weights[i])\n",
    "            counter_features.append(vec.get_feature_names()[i])\n",
    "co_weights = pd.DataFrame({\"Counter Features\": list(counter_features), \n",
    "                                  \"Features' Weights\": list(counter_weights)})\n",
    "co_weights = co_weights.sort_values(by=\"Features' Weights\", ascending=False)\n",
    "co_weights = pd.concat([co_weights.head(5),co_weights.tail(5)])\n",
    "plt.figure(num=None, figsize=(4, 3), dpi=200, facecolor='w', edgecolor='k')\n",
    "sns.barplot(x=\"Features' Weights\", y=\"Counter Features\", data=co_weights)\n",
    "#plt.xticks(rotation=90)\n",
    "#plt.title(str('Features not appearing in the instance'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(X_train)):\n",
    "    if 'teach' in X_train[i]:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[119]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, real_prediction, local_prediction = lionet_original.explain_instance(x_train[119][0:], 2000, transparent_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weights = pd.DataFrame({\"Features\": list(vec.get_feature_names()), \n",
    "                                \"Features' Weights\": list(weights*x_train[119][0:])})\n",
    "model_weights = model_weights.sort_values(by=\"Features' Weights\", ascending=False)\n",
    "model_weights = model_weights[(model_weights[\"Features' Weights\"] != 0)]    \n",
    "#model_weights, lime_predict([text])[0][1], rd.predict(texts)[0], weights\n",
    "plt.figure(num=None, figsize=(4, 3), dpi=200, facecolor='w', edgecolor='k')\n",
    "sns.barplot(x=\"Features' Weights\", y=\"Features\", data=model_weights)\n",
    "#plt.xticks(rotation=90)\n",
    "#plt.title(str('Features not appearing in the instance'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qualitative AutoLioNets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_instance = x_train[9].copy()\n",
    "transparent_model = Ridge(alpha=0.0001,fit_intercept=True,random_state=0)\n",
    "weights, real_prediction, local_prediction = lionet_best.explain_instance(temp_instance[0:],2000, transparent_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str('Sentence: \"' + X_train[9] + '\"   Class: ' + str(train_y[9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, real_prediction, local_prediction = lionet_best.explain_instance(x_train[9][0:], 2000, transparent_model)\n",
    "print(\"Real prediction:\",real_prediction,\", Local prediction:\",local_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weights = pd.DataFrame({\"Features\": list(vec.get_feature_names()), \n",
    "                              \"Features' Weights\": list(weights*x_train[9][0:])})\n",
    "model_weights = model_weights.sort_values(by=\"Features' Weights\", ascending=False)\n",
    "model_weights = model_weights[(model_weights[\"Features' Weights\"] != 0)]    \n",
    "#model_weights, lime_predict([text])[0][1], rd.predict(texts)[0], weights\n",
    "plt.figure(num=None, figsize=(4, 3), dpi=200, facecolor='w', edgecolor='k')\n",
    "sns.barplot(x=\"Features' Weights\", y=\"Features\", data=model_weights)\n",
    "#plt.xticks(rotation=90)\n",
    "#plt.title(str('Features not appearing in the instance'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(weights),np.argmin(weights),np.max(weights),np.min(weights),vec.get_feature_names()[np.argmax(weights)],vec.get_feature_names()[np.argmin(weights)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_weights = []\n",
    "counter_features = []\n",
    "for i in range(len(weights)):\n",
    "    if weights[i]!=0:\n",
    "        if vec.get_feature_names()[i] not in X_train[9]:\n",
    "            counter_weights.append(weights[i])\n",
    "            counter_features.append(vec.get_feature_names()[i])\n",
    "co_weights = pd.DataFrame({\"Counter Features\": list(counter_features), \n",
    "                                  \"Features' Weights\": list(counter_weights)})\n",
    "co_weights = co_weights.sort_values(by=\"Features' Weights\", ascending=False)\n",
    "co_weights = pd.concat([co_weights.head(5),co_weights.tail(5)])\n",
    "plt.figure(num=None, figsize=(4, 3), dpi=200, facecolor='w', edgecolor='k')\n",
    "sns.barplot(x=\"Features' Weights\", y=\"Counter Features\", data=co_weights)\n",
    "#plt.xticks(rotation=90)\n",
    "#plt.title(str('Features not appearing in the instance'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(X_train)):\n",
    "    if 'teach' in X_train[i]:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[119]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, real_prediction, local_prediction = lionet_best.explain_instance(x_train[119][0:], 2000, transparent_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weights = pd.DataFrame({\"Features\": list(vec.get_feature_names()), \n",
    "                              \"Features' Weights\": list(weights*x_train[119][0:])})\n",
    "model_weights = model_weights.sort_values(by=\"Features' Weights\", ascending=False)\n",
    "model_weights = model_weights[(model_weights[\"Features' Weights\"] != 0)]    \n",
    "#model_weights, lime_predict([text])[0][1], rd.predict(texts)[0], weights\n",
    "plt.figure(num=None, figsize=(4, 3), dpi=200, facecolor='w', edgecolor='k')\n",
    "sns.barplot(x=\"Features' Weights\", y=\"Features\", data=model_weights)\n",
    "#plt.xticks(rotation=90)\n",
    "#plt.title(str('Features not appearing in the instance'))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
